# Movie Recommendation System ğŸ¬

A robust, hybrid movie recommendation engine built with FastAPI, utilizing Content-Based filtering, Collaborative Filtering (SVD), and Popularity-based models.

## ğŸš€ Features

-   **Hybrid Recommendation Engine**: Combines multiple strategies for better accuracy.
    -   **Collaborative Filtering**: Personalized recommendations using SVD (Singular Value Decomposition).
    -   **Content-Based**: Recommendations based on movie similarity (genres, features).
    -   **Popularity-Based**: Top-rated movies for new users (Cold Start problem).
-   **FastAPI Backend**: High-performance, async-ready API.
-   **Git LFS Integration**: Efficient handling of large machine learning models (>100MB).
-   **Clean Architecture**: Modular code structure separating data processing, modeling, and API routes.

## ğŸ› ï¸ Tech Stack

-   **Python 3.10+**
-   **FastAPI** & **Uvicorn**
-   **Scikit-Learn** & **Surprise** (Recommendation algorithms)
-   **Pandas** & **Numpy** (Data manipulation)
-   **Git LFS** (Large File Storage)

## ğŸ“¦ Installation

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/Atharv-M/multi_recomendation_system-.git
    cd multi_recomendation_system-
    ```

2.  **Pull Large Model Files (Important!)**
    This project uses Git LFS for model files. Ensure you have `git-lfs` installed.
    ```bash
    git lfs install
    git lfs pull
    ```

3.  **Install Dependencies**
    It is recommended to use a virtual environment.
    ```bash
    # Create virtual environment
    python -m venv .venv
    
    # Activate virtual environment
    # Windows:
    # .venv\Scripts\activate
    # Mac/Linux:
    source .venv/bin/activate
    
    # Install packages
    pip install -r requirements.txt
    ```

## ğŸš€ Running the API

Start the FastAPI server:

```bash
uvicorn app.main:app --reload
```

The API will be available at:
-   **API Root**: [`http://127.0.0.1:8000/`](http://127.0.0.1:8000/)
-   **Interactive Docs (Swagger UI)**: [`http://127.0.0.1:8000/docs`](http://127.0.0.1:8000/docs)

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ app/                        # Main FastAPI application
â”‚   â”œâ”€â”€ auth/                   # Authentication module
â”‚   â”‚   â””â”€â”€ supabase_auth.py    # Supabase authentication integration
â”‚   â”œâ”€â”€ routes/                 # API route definitions
â”‚   â”‚   â””â”€â”€ recommend.py        # Recommendation API endpoints
â”‚   â”œâ”€â”€ config.py               # Application configuration settings
â”‚   â”œâ”€â”€ dependencies.py         # Dependency injection logic
â”‚   â”œâ”€â”€ main.py                 # App entry point (Uvicorn app instance)
â”‚   â””â”€â”€ schemas.py              # Pydantic models for request/response validation
â”‚
â”œâ”€â”€ artifacts/                  # Trained models and data artifacts (Git LFS tracked)
â”‚   â”œâ”€â”€ collaborative/          # Collaborative filtering (SVD) artifacts
â”‚   â”‚   â”œâ”€â”€ movies_df.pkl       # Movies dataframe for CF
â”‚   â”‚   â””â”€â”€ svd_model.pkl       # Serialized SVD model
â”‚   â”œâ”€â”€ content/                # Content-based filtering artifacts
â”‚   â”‚   â”œâ”€â”€ movies_index.pkl    # Movie index mapping
â”‚   â”‚   â””â”€â”€ topk_movie_similarity.joblib # Precomputed similarity matrix
â”‚   â”œâ”€â”€ metadata/               # Metadata for movies
â”‚   â”‚   â””â”€â”€ movies_df.pkl       # Enriched movies dataframe
â”‚   â”œâ”€â”€ popularity/             # Popularity-based model artifacts
â”‚   â”‚   â””â”€â”€ popularity_ranked.pkl # Ranked popular movies list
â”‚   â””â”€â”€ saved_features/         # Feature engineering artifacts
â”‚       â”œâ”€â”€ mlb.joblib          # MultiLabelBinarizer for genres
â”‚       â”œâ”€â”€ movie_features.joblib # Processed movie features
â”‚       â”œâ”€â”€ scaler.joblib       # Standard scaler for normalization
â”‚       â””â”€â”€ tfidf.joblib        # TF-IDF vectorizer model
â”‚
â”œâ”€â”€ data/                       # Data storage directory
â”‚   â”œâ”€â”€ processed/              # Cleaned and processed datasets
â”‚   â”‚   â””â”€â”€ master_dataset.csv  # Final dataset for modeling
â”‚   â””â”€â”€ raw/                    # Raw MovieLens source data
â”‚       â”œâ”€â”€ genome_scores.csv   # Tag relevance scores
â”‚       â”œâ”€â”€ genome_tags.csv     # Tag descriptions
â”‚       â”œâ”€â”€ link.csv            # IMDb/TMDB ID links
â”‚       â”œâ”€â”€ movie.csv           # Movie titles and genres
â”‚       â”œâ”€â”€ rating.csv          # User ratings
â”‚       â””â”€â”€ tag.csv             # User-assigned tags
â”‚
â”œâ”€â”€ src/                        # Data Science Pipeline source code
â”‚   â”œâ”€â”€ data/                   # Data processing scripts
â”‚   â”‚   â””â”€â”€ build_dataset.py    # Script to build and clean datasets
â”‚   â”œâ”€â”€ features/               # Feature engineering scripts
â”‚   â”‚   â””â”€â”€ build_features.py   # Script to generate model features
â”‚   â”œâ”€â”€ models/                 # Recommendation model definitions
â”‚   â”‚   â”œâ”€â”€ collaborative_filtering.py # SVD implementation
â”‚   â”‚   â”œâ”€â”€ content_based_model.py     # Content-based logic
â”‚   â”‚   â”œâ”€â”€ hybrid_recomender.py       # Hybrid model orchestrator
â”‚   â”‚   â””â”€â”€ popularity_model.py        # Popularity baseline model
â”‚   â””â”€â”€ config.py               # Pipeline configuration
â”‚
â”œâ”€â”€ data_cleaning.ipynb         # Notebook for data exploration and cleaning
â”œâ”€â”€ training.ipynb              # Notebook for model training and evaluation
â”œâ”€â”€ main.py                     # Script entry point (local testing)
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # Project documentation
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
